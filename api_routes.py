"""REST API routes for the RAG application frontend.

These endpoints are used by the React frontend to:
- Manage projects
- Manage chats (standalone and project chats)
- Upload/list scoped documents
- Send queries (via Inngest events)
"""
from fastapi import APIRouter, HTTPException, UploadFile, File, Request, Depends
from pydantic import BaseModel
from typing import Optional
from datetime import datetime, timezone
from pymongo import MongoClient
from dotenv import load_dotenv
import os
import inngest
import logging

load_dotenv()

# Module logger
logger = logging.getLogger(__name__)

from models import (
    Project,
    Chat,
    Document,
    Message,
    MessageRole,
    ScopeType,
    AIModel,
    User,
    generate_id,
)
from auth_routes import get_current_user

# Router for API endpoints
router = APIRouter(prefix="/api", tags=["api"])

# MongoDB client
def get_db():
    uri = os.getenv("MONGODB_URI")
    if not uri:
        raise HTTPException(status_code=500, detail="MONGODB_URI not configured")
    client = MongoClient(uri)
    db_name = os.getenv("MONGODB_DATABASE", "docurag")  # Use env variable, default to docurag
    return client[db_name]


# --- Plan Limits ---
# Resource limits per plan
PLAN_LIMITS = {
    "free": {"projects": 1, "chats": 3, "documents": 3, "docs_per_scope": 1, "token_limit": 10000},
    "pro": {"projects": 10, "chats": None, "documents": 30, "docs_per_scope": 5, "token_limit": 500000},  # None = unlimited
    "premium": {"projects": None, "chats": None, "documents": None, "docs_per_scope": 10, "token_limit": 2000000},
}


# --- Request Models ---

class CreateProjectRequest(BaseModel):
    name: str = "New Project"

class CreateChatRequest(BaseModel):
    project_id: Optional[str] = None  # None = standalone chat
    title: str = "New Chat"

class UpdateChatRequest(BaseModel):
    title: Optional[str] = None
    is_pinned: Optional[bool] = None
    model: Optional[str] = None  # AI model selection
    quality_preset: Optional[str] = None  # quick, standard, thorough, deep, max

class SaveMessageRequest(BaseModel):
    chat_id: str
    role: str
    content: str
    sources: list[str] = []


# --- Project Endpoints ---

@router.post("/projects")
async def create_project(request: CreateProjectRequest, user: User = Depends(get_current_user)):
    """Create a new project for the current user."""
    db = get_db()
    
    # Check project limit for user's plan
    plan = user.plan or "free"
    limit = PLAN_LIMITS.get(plan, PLAN_LIMITS["free"])["projects"]
    if limit is not None:
        current_count = db.projects.count_documents({"user_id": user.id})
        if current_count >= limit:
            raise HTTPException(
                status_code=403, 
                detail={"error": "limit_reached", "resource": "projects", "limit": limit}
            )
    
    project = Project(user_id=user.id, name=request.name)
    db.projects.insert_one(project.model_dump())
    return project.model_dump()

@router.get("/projects")
async def list_projects(user: User = Depends(get_current_user)):
    """List all projects for the current user."""
    db = get_db()
    projects = list(db.projects.find({"user_id": user.id}, {"_id": 0}))
    return projects

@router.get("/projects/{project_id}")
async def get_project(project_id: str, user: User = Depends(get_current_user)):
    """Get a specific project owned by the current user."""
    db = get_db()
    project = db.projects.find_one({"id": project_id, "user_id": user.id}, {"_id": 0})
    if not project:
        raise HTTPException(status_code=404, detail="Project not found")
    return project

@router.delete("/projects/{project_id}")
async def delete_project(project_id: str, user: User = Depends(get_current_user)):
    """Delete a project and all associated data (documents, chunks, vectors, S3).
    
    Deletion order (per document):
    1. Vector embeddings (by document_id)
    2. Chunks (by document_id)
    3. S3 file (by s3_key)
    Then: document metadata, scope links, messages, chats, project
    """
    from vector_db import MongoDBStorage
    from document_service import safe_delete_document
    
    db = get_db()
    
    # Verify user owns the project
    project = db.projects.find_one({"id": project_id, "user_id": user.id})
    if not project:
        raise HTTPException(status_code=404, detail="Project not found")
    
    vector_store = MongoDBStorage()
    total_deleted = 0
    all_doc_ids = []
    
    # 1. Get and delete project-level documents via document_scopes
    project_scope_links = list(db.document_scopes.find({"scope_type": "project", "scope_id": project_id}))
    project_doc_ids = [link["document_id"] for link in project_scope_links]
    project_docs = list(db.documents.find({"id": {"$in": project_doc_ids}})) if project_doc_ids else []
    
    for doc in project_docs:
        if safe_delete_document(db, vector_store, file_storage, doc, project_id):
            total_deleted += 1
            all_doc_ids.append(doc["id"])
    
    # 2. Delete all chats and their documents
    chats = list(db.chats.find({"project_id": project_id}))
    for chat in chats:
        # Get chat documents via document_scopes
        chat_scope_links = list(db.document_scopes.find({"scope_type": "chat", "scope_id": chat["id"]}))
        chat_doc_ids = [link["document_id"] for link in chat_scope_links]
        chat_docs = list(db.documents.find({"id": {"$in": chat_doc_ids}})) if chat_doc_ids else []
        
        for doc in chat_docs:
            if safe_delete_document(db, vector_store, file_storage, doc, chat["id"]):
                total_deleted += 1
                all_doc_ids.append(doc["id"])
        
        # Delete scope links and messages for this chat
        db.document_scopes.delete_many({"scope_type": "chat", "scope_id": chat["id"]})
        db.messages.delete_many({"chat_id": chat["id"]})
    
    # 3. Delete document metadata
    if all_doc_ids:
        db.documents.delete_many({"id": {"$in": all_doc_ids}})
    
    # Delete project scope links
    db.document_scopes.delete_many({"scope_type": "project", "scope_id": project_id})
    
    # Delete chats and project
    db.chats.delete_many({"project_id": project_id})
    db.projects.delete_one({"id": project_id})
    
    # 4. Decrement user's active document count (with safety guard)
    if total_deleted > 0:
        db.users.update_one(
            {"id": user.id, "active_documents_count": {"$gte": total_deleted}},
            {"$inc": {"active_documents_count": -total_deleted}}
        )
    
    return {"status": "deleted"}


# --- Chat Endpoints ---

@router.post("/chats")
async def create_chat(request: CreateChatRequest, user: User = Depends(get_current_user)):
    """Create a new chat for the current user."""
    db = get_db()
    
    # Check chat limit for user's plan
    plan = user.plan or "free"
    limit = PLAN_LIMITS.get(plan, PLAN_LIMITS["free"])["chats"]
    if limit is not None:
        current_count = db.chats.count_documents({"user_id": user.id})
        if current_count >= limit:
            raise HTTPException(
                status_code=403, 
                detail={"error": "limit_reached", "resource": "chats", "limit": limit}
            )
    
    # If project_id provided, verify user owns the project
    if request.project_id:
        project = db.projects.find_one({"id": request.project_id, "user_id": user.id})
        if not project:
            raise HTTPException(status_code=404, detail="Project not found")
    
    chat = Chat(
        user_id=user.id,
        project_id=request.project_id,
        title=request.title
    )
    db.chats.insert_one(chat.model_dump())
    return chat.model_dump()

@router.get("/chats")
async def list_chats(user: User = Depends(get_current_user), project_id: Optional[str] = None, standalone: bool = False):
    """List chats for the current user. Filter by project_id or get standalone chats."""
    db = get_db()
    query = {"user_id": user.id}
    
    if standalone:
        query["project_id"] = None
    elif project_id:
        query["project_id"] = project_id
    
    chats = list(db.chats.find(query, {"_id": 0}))
    return chats

@router.get("/chats/{chat_id}")
async def get_chat(chat_id: str, user: User = Depends(get_current_user)):
    """Get a specific chat owned by the current user."""
    db = get_db()
    chat = db.chats.find_one({"id": chat_id, "user_id": user.id}, {"_id": 0})
    if not chat:
        raise HTTPException(status_code=404, detail="Chat not found")
    return chat

@router.patch("/chats/{chat_id}")
async def update_chat(chat_id: str, request: UpdateChatRequest, user: User = Depends(get_current_user)):
    """Update chat title, pinned status, model, or quality preset."""
    db = get_db()
    
    # Verify user owns the chat
    chat = db.chats.find_one({"id": chat_id, "user_id": user.id})
    if not chat:
        raise HTTPException(status_code=404, detail="Chat not found")
    
    updates = {}
    if request.title is not None:
        updates["title"] = request.title
    if request.is_pinned is not None:
        updates["is_pinned"] = request.is_pinned
    if request.model is not None:
        # Validate model enum
        try:
            AIModel(request.model)
            updates["model"] = request.model
        except ValueError:
            raise HTTPException(status_code=400, detail=f"Invalid model: {request.model}")
    if request.quality_preset is not None:
        # Validate preset
        valid_presets = ["quick", "standard", "thorough", "deep", "max"]
        if request.quality_preset not in valid_presets:
            raise HTTPException(status_code=400, detail=f"Invalid preset: {request.quality_preset}")
        updates["quality_preset"] = request.quality_preset
    
    if updates:
        db.chats.update_one({"id": chat_id}, {"$set": updates})
    
    # Return updated chat
    updated_chat = db.chats.find_one({"id": chat_id}, {"_id": 0})
    return updated_chat

@router.delete("/chats/{chat_id}")
async def delete_chat(chat_id: str, user: User = Depends(get_current_user)):
    """Delete a chat and all associated data (documents, chunks, vectors, S3).
    
    Deletion order (per document):
    1. Vector embeddings (by document_id)
    2. Chunks (by document_id)
    3. S3 file (by s3_key)
    Then: document metadata, scope links, messages, chat
    """
    from vector_db import MongoDBStorage
    from document_service import safe_delete_document
    
    db = get_db()
    
    # Verify user owns the chat
    chat = db.chats.find_one({"id": chat_id, "user_id": user.id})
    if not chat:
        raise HTTPException(status_code=404, detail="Chat not found")
    
    vector_store = MongoDBStorage()
    
    # Get document IDs via document_scopes junction table
    scope_links = list(db.document_scopes.find({"scope_type": "chat", "scope_id": chat_id}))
    doc_ids = [link["document_id"] for link in scope_links]
    
    # Get actual documents
    chat_docs = list(db.documents.find({"id": {"$in": doc_ids}})) if doc_ids else []
    
    # Delete each document using helper (vectors, chunks, S3)
    deleted_count = 0
    for doc in chat_docs:
        if safe_delete_document(db, vector_store, file_storage, doc, chat_id):
            deleted_count += 1
    
    # Delete document metadata
    if doc_ids:
        db.documents.delete_many({"id": {"$in": doc_ids}})
    
    # Delete scope links
    db.document_scopes.delete_many({"scope_type": "chat", "scope_id": chat_id})
    
    # Delete messages and chat
    db.messages.delete_many({"chat_id": chat_id})
    db.chats.delete_one({"id": chat_id})
    
    # Decrement user's active document count (with $gte safety guard)
    if deleted_count > 0:
        db.users.update_one(
            {"id": user.id, "active_documents_count": {"$gte": deleted_count}},
            {"$inc": {"active_documents_count": -deleted_count}}
        )
    
    return {"status": "deleted"}


# --- Message Endpoints ---

@router.get("/chats/{chat_id}/messages")
def get_messages(chat_id: str):
    """Get messages for a chat."""
    db = get_db()
    messages = list(db.messages.find({"chat_id": chat_id}, {"_id": 0}).sort("timestamp", 1))
    return messages

@router.post("/messages")
def save_message(request: SaveMessageRequest):
    """Save a message to a chat."""
    db = get_db()
    
    # Validate role
    try:
        role = MessageRole(request.role)
    except ValueError:
        raise HTTPException(status_code=400, detail=f"Invalid role: {request.role}")
    
    message = Message(
        chat_id=request.chat_id,
        role=role,
        content=request.content,
        sources=request.sources
    )
    db.messages.insert_one(message.model_dump())
    
    # Auto-update chat title on first user message
    chat = db.chats.find_one({"id": request.chat_id})
    if chat and chat.get("title") == "New Chat" and role == MessageRole.USER:
        new_title = request.content[:50] + ("..." if len(request.content) > 50 else "")
        db.chats.update_one({"id": request.chat_id}, {"$set": {"title": new_title}})
    
    return message.model_dump()


# --- Document Endpoints ---

@router.get("/documents")
def list_documents(scope_type: str, scope_id: str):
    """List documents for a scope (chat or project) via DocumentScope."""
    db = get_db()
    
    # Get document_ids linked to this scope (M1 architecture)
    scope_links = list(db.document_scopes.find(
        {"scope_type": scope_type, "scope_id": scope_id},
        {"document_id": 1}
    ))
    doc_ids = [s["document_id"] for s in scope_links]
    
    if not doc_ids:
        return []
    
    # Get document details
    docs = list(db.documents.find(
        {"id": {"$in": doc_ids}},
        {"_id": 0}
    ))
    return docs

@router.get("/chats/{chat_id}/documents")
def get_chat_documents(chat_id: str, include_project: bool = True):
    """Get documents for a chat, optionally including project docs."""
    db = get_db()
    
    # Get chat document_ids via DocumentScope
    chat_links = list(db.document_scopes.find(
        {"scope_type": "chat", "scope_id": chat_id},
        {"document_id": 1}
    ))
    doc_ids = [s["document_id"] for s in chat_links]
    
    # If chat belongs to a project, include project docs
    if include_project:
        chat = db.chats.find_one({"id": chat_id})
        if chat and chat.get("project_id"):
            project_links = list(db.document_scopes.find(
                {"scope_type": "project", "scope_id": chat["project_id"]},
                {"document_id": 1}
            ))
            doc_ids.extend([s["document_id"] for s in project_links])
    
    if not doc_ids:
        return []
    
    # Get unique document details
    docs = list(db.documents.find(
        {"id": {"$in": list(set(doc_ids))}},
        {"_id": 0}
    ))
    return docs


# --- Upload Limits (easily configurable) ---
import file_storage

MAX_FILE_SIZE = 10 * 1024 * 1024  # 10 MB per individual file
MAX_PDFS_PER_SCOPE = 10  # Maximum number of PDFs per chat/project
MAX_TOTAL_SIZE_PER_SCOPE = 50 * 1024 * 1024  # 50 MB total per chat/project

# PDF magic bytes
PDF_MAGIC_BYTES = [b'%PDF', b'\x25\x50\x44\x46']


def validate_pdf_content(content: bytes) -> bool:
    """Validate that file content starts with PDF magic bytes."""
    if len(content) < 4:
        return False
    header = content[:4]
    return any(header.startswith(magic) for magic in PDF_MAGIC_BYTES)


@router.get("/upload-limits")
def get_upload_limits(scope_type: str, scope_id: str, user: User = Depends(get_current_user)):
    """Get upload limits and current usage for a scope.
    
    Returns max files, max total size, and current usage.
    """
    from models import ScopeType
    
    try:
        ScopeType(scope_type)
    except ValueError:
        raise HTTPException(status_code=400, detail="scope_type must be 'chat' or 'project'")
    
    db = get_db()
    
    # Get plan-based document limit per scope
    plan = user.plan or "free"
    max_docs_per_scope = PLAN_LIMITS.get(plan, PLAN_LIMITS["free"])["docs_per_scope"]
    
    # Get current usage
    scope_docs = list(db.document_scopes.aggregate([
        {"$match": {"scope_type": scope_type, "scope_id": scope_id}},
        {"$lookup": {
            "from": "documents",
            "localField": "document_id",
            "foreignField": "id",
            "as": "doc"
        }},
        {"$unwind": "$doc"},
        {"$group": {
            "_id": None,
            "count": {"$sum": 1},
            "total_size": {"$sum": "$doc.size_bytes"}
        }}
    ]))
    
    current_count = scope_docs[0]["count"] if scope_docs else 0
    current_size = scope_docs[0]["total_size"] if scope_docs else 0
    
    return {
        "max_files": max_docs_per_scope,
        "max_file_size": MAX_FILE_SIZE,
        "max_total_size": MAX_TOTAL_SIZE_PER_SCOPE,
        "current_count": current_count,
        "current_size": current_size,
        "remaining_count": max_docs_per_scope - current_count,
        "remaining_size": MAX_TOTAL_SIZE_PER_SCOPE - current_size
    }


@router.post("/upload")
async def upload_document(
    request: Request,
    scope_type: str,
    scope_id: str,
    file: UploadFile = File(...),
    user: User = Depends(get_current_user)
):
    """Upload a PDF document to a scope (chat or project).
    
    scope_type: 'chat' or 'project'
    scope_id: The ID of the chat or project
    """
    # Validate scope_type
    try:
        scope = ScopeType(scope_type)
    except ValueError:
        raise HTTPException(status_code=400, detail="scope_type must be 'chat' or 'project'")
    
    # Validate scope exists and user owns it
    db = get_db()
    if scope_type == "chat":
        chat = db.chats.find_one({"id": scope_id, "user_id": user.id})
        if not chat:
            raise HTTPException(status_code=404, detail="Chat not found")
    elif scope_type == "project":
        project = db.projects.find_one({"id": scope_id, "user_id": user.id})
        if not project:
            raise HTTPException(status_code=404, detail="Project not found")
    
    # Get plan-based document limit per scope
    plan = user.plan or "free"
    max_docs_per_scope = PLAN_LIMITS.get(plan, PLAN_LIMITS["free"])["docs_per_scope"]
    
    # Check overall document limit (active_documents_count)
    max_total_docs = PLAN_LIMITS.get(plan, PLAN_LIMITS["free"])["documents"]
    current_active = getattr(user, 'active_documents_count', 0) or 0
    if max_total_docs is not None and current_active >= max_total_docs:
        raise HTTPException(
            status_code=403,
            detail={"error": "limit_reached", "resource": "documents", "limit": max_total_docs}
        )
    
    # Check scope limits (count and total size)
    scope_docs = list(db.document_scopes.aggregate([
        {"$match": {"scope_type": scope_type, "scope_id": scope_id}},
        {"$lookup": {
            "from": "documents",
            "localField": "document_id",
            "foreignField": "id",
            "as": "doc"
        }},
        {"$unwind": "$doc"},
        {"$group": {
            "_id": None,
            "count": {"$sum": 1},
            "total_size": {"$sum": "$doc.size_bytes"}
        }}
    ]))
    
    current_count = scope_docs[0]["count"] if scope_docs else 0
    current_size = scope_docs[0]["total_size"] if scope_docs else 0
    
    if current_count >= max_docs_per_scope:
        raise HTTPException(
            status_code=403, 
            detail={"error": "limit_reached", "resource": "documents", "limit": max_docs_per_scope}
        )
    
    # Check file extension
    if not file.filename or not file.filename.lower().endswith('.pdf'):
        raise HTTPException(status_code=400, detail="Only PDF files are allowed")
    
    # Read file content
    content = await file.read()
    
    # Check file size
    if len(content) > MAX_FILE_SIZE:
        raise HTTPException(status_code=400, detail=f"File too large. Maximum size is {MAX_FILE_SIZE // (1024*1024)}MB per file")
    
    # Check total size limit for scope
    if current_size + len(content) > MAX_TOTAL_SIZE_PER_SCOPE:
        remaining = (MAX_TOTAL_SIZE_PER_SCOPE - current_size) // (1024 * 1024)
        raise HTTPException(
            status_code=400, 
            detail=f"Total size limit exceeded. Only {remaining}MB remaining for this {scope_type}"
        )
    
    # Validate PDF magic bytes
    if not validate_pdf_content(content):
        raise HTTPException(status_code=400, detail="Invalid PDF file content")
    
    # Sanitize filename
    import re
    import hashlib
    safe_filename = re.sub(r'[^\w\s\-\.]', '', file.filename)
    if not safe_filename or safe_filename != file.filename:
        safe_filename = re.sub(r'[^\w\-\.]', '_', file.filename)
    
    # Calculate checksum for deduplication
    checksum = "sha256:" + hashlib.sha256(content).hexdigest()
    
    # Check for existing document with same checksum (M1 deduplication)
    db = get_db()
    existing_doc = db.documents.find_one({"checksum": checksum})
    
    if existing_doc:
        # Document exists, just add scope link
        from models import DocumentScope, Document
        
        # Serialize existing doc to handle ObjectId/datetime
        existing_doc_model = Document(**existing_doc)
        
        scope_link = DocumentScope(
            document_id=existing_doc_model.id,
            scope_type=scope,
            scope_id=scope_id
        )
        db.document_scopes.insert_one(scope_link.model_dump())
        
        return {
            "document": existing_doc_model.model_dump(),
            "status": "linked",
            "message": "Document already exists, linked to scope"
        }
    
    # Upload to S3 with scope prefix
    prefix = f"{scope_type}s/{scope_id}/"
    result = file_storage.upload_file(content, safe_filename, prefix)
    
    # Create document record (M1 model)
    from models import Document, DocumentScope, DocumentStatus
    doc = Document(
        filename=safe_filename,
        s3_key=result["s3_key"],
        checksum=checksum,
        size_bytes=len(content),
        status=DocumentStatus.PENDING
    )
    db.documents.insert_one(doc.model_dump())
    
    # Create scope link (M1 DocumentScope)
    scope_link = DocumentScope(
        document_id=doc.id,
        scope_type=scope,
        scope_id=scope_id
    )
    db.document_scopes.insert_one(scope_link.model_dump())
    
    # Increment user's active document count AFTER successful commit
    db.users.update_one(
        {"id": user.id},
        {"$inc": {"active_documents_count": 1}}
    )
    
    return {
        "document": doc.model_dump(),
        "s3_url": result["url"],
        "status": "uploaded"
    }


# --- Inngest Event Endpoints ---

def get_inngest_client():
    return inngest.Inngest(app_id="rag-app", is_production=False)


class IngestEventRequest(BaseModel):
    pdf_path: str
    filename: str
    scope_type: str
    scope_id: str
    document_id: str  # M1: Required for chunk linking


class QueryEventRequest(BaseModel):
    question: str
    chat_id: str
    scope_type: str
    scope_id: str
    model: str = "deepseek"  # AI model to use
    top_k: int = 5
    history: list[dict] = []


@router.post("/events/ingest")
async def send_ingest_event(request: IngestEventRequest):
    """Send an ingestion event to Inngest."""
    client = get_inngest_client()
    
    event = inngest.Event(
        name="rag/ingest_pdf",
        data={
            "pdf_path": request.pdf_path,
            "filename": request.filename,
            "scope_type": request.scope_type,
            "scope_id": request.scope_id,
            "document_id": request.document_id,  # M1: Include for chunk linking
        }
    )
    
    ids = await client.send(event)
    return {"event_ids": ids}


@router.post("/events/query")
async def send_query_event(request: QueryEventRequest, user: User = Depends(get_current_user)):
    """Send a query event to Inngest."""
    # Get plan-based token limit (not from DB - use dynamic calculation)
    plan = getattr(user, 'plan', 'free') or 'free'
    token_limit = PLAN_LIMITS.get(plan, PLAN_LIMITS["free"])["token_limit"]
    tokens_used = getattr(user, 'tokens_used', 0) or 0
    
    if tokens_used >= token_limit:
        raise HTTPException(
            status_code=403,
            detail={"error": "limit_reached", "resource": "tokens", "limit": token_limit, "used": tokens_used}
        )
    
    # Validate model enum
    try:
        AIModel(request.model)
    except ValueError:
        raise HTTPException(status_code=400, detail=f"Invalid model: {request.model}")
    
    client = get_inngest_client()
    
    event = inngest.Event(
        name="rag/query_pdf_ai",
        data={
            "question": request.question,
            "chat_id": request.chat_id,
            "scope_type": request.scope_type,
            "scope_id": request.scope_id,
            "model": request.model,
            "top_k": request.top_k,
            "history": request.history,
            "user_id": user.id,  # For token tracking
        }
    )
    
    ids = await client.send(event)
    return {"event_ids": ids}


# --- Streaming Chat Endpoint ---

from sse_starlette.sse import EventSourceResponse
import httpx
import json as json_lib
import asyncio

# Import history sliding window from main
def get_recent_history_local(messages: list, max_messages: int = 10, max_tokens: int = 4000) -> list:
    """Get recent conversation history with sliding window."""
    if not messages:
        return []
    recent = messages[-max_messages:] if len(messages) > max_messages else messages[:]
    # Estimate tokens
    text = "".join(m.get("content", "") for m in recent)
    token_count = len(text) // 4
    while token_count > max_tokens and len(recent) > 2:
        recent = recent[2:]
        text = "".join(m.get("content", "") for m in recent)
        token_count = len(text) // 4
    return recent


class StreamQueryRequest(BaseModel):
    question: str
    history: list = []
    top_k: int = 10
    user_id: Optional[str] = None


@router.post("/chat/{chat_id}/stream")
async def stream_query(chat_id: str, request: StreamQueryRequest, user: User = Depends(get_current_user)):
    """Stream LLM response using Server-Sent Events."""
    
    # Check token limit
    plan = getattr(user, 'plan', 'free') or 'free'
    token_limit = PLAN_LIMITS.get(plan, PLAN_LIMITS["free"])["token_limit"]
    tokens_used = getattr(user, 'tokens_used', 0) or 0
    
    if tokens_used >= token_limit:
        async def limit_error():
            yield {
                "event": "error",
                "data": json_lib.dumps({"error": "limit_reached", "resource": "tokens", "limit": token_limit, "used": tokens_used})
            }
        return EventSourceResponse(limit_error())
    
    async def event_generator():
        try:
            # Step 1: Emit searching status
            yield {
                "event": "status",
                "data": json_lib.dumps({"stage": "searching", "message": "Searching documents..."})
            }
            
            # Step 2: Get chat and scope info
            db = get_db()
            chat = db.chats.find_one({"id": chat_id})
            if not chat:
                yield {"event": "error", "data": json_lib.dumps({"error": "Chat not found"})}
                return
            
            # Verify user owns this chat
            if chat.get("user_id") != user.id:
                yield {"event": "error", "data": json_lib.dumps({"error": "Access denied"})}
                return
            
            scope_type = "chat"
            scope_id = chat_id
            project_id = chat.get("project_id")
            
            # Step 3: Embed and search
            from data_loader import embed_texts
            from chunk_search import search_for_scope
            
            query_vec = embed_texts([request.question])[0]
            
            search_result = search_for_scope(
                query_vec,
                scope_type=scope_type,
                scope_id=scope_id,
                top_k=request.top_k,
                include_project=True,
                project_id=project_id
            )
            
            contexts = search_result.get("contexts", [])
            sources = search_result.get("sources", [])
            scores = search_result.get("scores", [])
            
            # Step 4: Emit sources immediately
            yield {
                "event": "sources",
                "data": json_lib.dumps({
                    "sources": sources,
                    "num_contexts": len(contexts),
                    "scores": scores
                })
            }
            
            # Handle empty results
            if not contexts or (scores and all(s < 0.3 for s in scores)):
                no_answer = "I couldn't find relevant information in your documents to answer this question."
                yield {
                    "event": "chunk",
                    "data": json_lib.dumps({"content": no_answer})
                }
                yield {
                    "event": "done",
                    "data": json_lib.dumps({"full_response": no_answer, "tokens_used": 0, "sources": []})
                }
                return
            
            # Step 5: Emit generating status
            yield {
                "event": "status", 
                "data": json_lib.dumps({"stage": "generating", "message": "Generating response..."})
            }
            
            # Step 6: Build prompt
            context_blocks = []
            for i, ctx in enumerate(contexts):
                source = sources[i] if i < len(sources) else "Unknown"
                score = scores[i] if i < len(scores) else 0.0
                context_blocks.append(f"---\nSource: {source} (Relevance: {score:.0%})\n{ctx}")
            context_block = "\n\n".join(context_blocks)
            
            system_prompt = """You are a helpful document assistant for Querious. Answer questions based ONLY on the provided context.
Rules:
- Only use information from the provided context
- If the context doesn't contain enough information, say so clearly  
- Cite sources using [source: filename, page X] format
- Be concise but thorough"""

            messages = [{"role": "system", "content": system_prompt}]
            
            # Apply sliding window to history
            recent_history = get_recent_history_local(request.history)
            messages.extend(recent_history)
            messages.append({
                "role": "user", 
                "content": f"Based on the following context:\n\n{context_block}\n\n---\nQuestion: {request.question}\n\nProvide a clear answer. Cite sources when referencing information."
            })
            
            # Step 7: Stream from DeepSeek
            async with httpx.AsyncClient(timeout=60.0) as client:
                async with client.stream(
                    "POST",
                    "https://api.deepseek.com/v1/chat/completions",
                    headers={
                        "Authorization": f"Bearer {os.getenv('DEEPSEEK_API_KEY')}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": "deepseek-chat",
                        "messages": messages,
                        "stream": True,
                        "temperature": 0.3,
                        "max_tokens": 2048,
                    }
                ) as response:
                    full_response = ""
                    async for line in response.aiter_lines():
                        if line.startswith("data: "):
                            data = line[6:]
                            if data == "[DONE]":
                                break
                            try:
                                chunk = json_lib.loads(data)
                                content = chunk["choices"][0]["delta"].get("content", "")
                                if content:
                                    full_response += content
                                    yield {
                                        "event": "chunk",
                                        "data": json_lib.dumps({"content": content})
                                    }
                            except json_lib.JSONDecodeError:
                                continue
            
            # Step 8: Calculate tokens (input + output)
            # Count input tokens: system prompt + context + history + user message
            input_text = system_prompt + context_block + request.question
            for msg in recent_history:
                input_text += msg.get("content", "")
            
            # Estimate: words Ã— 1.3 (average tokens per word for English)
            input_tokens = int(len(input_text.split()) * 1.3)
            output_tokens = int(len(full_response.split()) * 1.3)
            total_tokens = input_tokens + output_tokens
            
            yield {
                "event": "done",
                "data": json_lib.dumps({
                    "full_response": full_response,
                    "tokens_used": total_tokens,
                    "input_tokens": input_tokens,
                    "output_tokens": output_tokens,
                    "sources": sources
                })
            }
            
            # Step 9: Update token usage in database
            if request.user_id or user.id:
                uid = request.user_id or user.id
                db.users.update_one(
                    {"id": uid},
                    {"$inc": {"tokens_used": total_tokens}}
                )
                logger.info("Updated tokens_used for user %s: +%d (input: %d, output: %d)", 
                           uid, total_tokens, input_tokens, output_tokens)
                
        except Exception as e:
            yield {
                "event": "error",
                "data": json_lib.dumps({"error": str(e)})
            }
    
    return EventSourceResponse(event_generator())


# --- Legacy Endpoints (for backward compatibility during migration) ---

# Keep workspace endpoints for existing data
@router.get("/workspaces")
def list_workspaces():
    """DEPRECATED: List workspaces. Use /projects instead."""
    db = get_db()
    workspaces = list(db.workspaces.find({}, {"_id": 0}))
    return workspaces

@router.get("/workspaces/{workspace_id}")
def get_workspace(workspace_id: str):
    """DEPRECATED: Get workspace. Use /projects/{id} instead."""
    db = get_db()
    workspace = db.workspaces.find_one({"id": workspace_id}, {"_id": 0})
    if not workspace:
        raise HTTPException(status_code=404, detail="Workspace not found")
    return workspace

@router.get("/sessions/{session_id}")
def get_session(session_id: str):
    """DEPRECATED: Get session. Use /chats/{id} instead."""
    db = get_db()
    session = db.chat_sessions.find_one({"id": session_id}, {"_id": 0})
    if not session:
        raise HTTPException(status_code=404, detail="Session not found")
    return session

@router.delete("/sessions/{session_id}")
def delete_session(session_id: str):
    """DEPRECATED: Delete session. Use /chats/{id} instead."""
    db = get_db()
    db.chat_sessions.delete_one({"id": session_id})
    db.messages.delete_many({"session_id": session_id})
    return {"status": "deleted"}
